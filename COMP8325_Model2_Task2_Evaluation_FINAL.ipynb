{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f146c28d",
   "metadata": {},
   "source": [
    "# COMP8325 Group Project - Model 2 and Task 2 Evaluation\n",
    "This notebook includes:\n",
    "- Training XGBoost (Model 2) on the BODMAS dataset\n",
    "- Saving the model\n",
    "- Evaluating on holdout dataset\n",
    "- Generating predictions and performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f09d31cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Model 2 training and Task 2 evaluation...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "print(\"ðŸš€ Starting Model 2 training and Task 2 evaluation...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1d7013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_data = np.load('bodmas_train_test.npz')\n",
    "X_all = train_data['X']\n",
    "y_binary = train_data['y']\n",
    "\n",
    "metadata = pd.read_csv('bodmas_metadata_train_test.csv')\n",
    "category_labels = pd.read_csv('bodmas_malware_category.csv')\n",
    "\n",
    "# Fix: rename metadata column to match category_labels for merge\n",
    "metadata = metadata.rename(columns={'sha': 'sha256'})\n",
    "metadata = metadata.dropna(subset=['sha256'])\n",
    "category_labels = category_labels.dropna(subset=['sha256'])\n",
    "merged = metadata.merge(category_labels, on='sha256', how='inner')\n",
    "\n",
    "X = X_all[merged.index]\n",
    "y = merged['category'].astype('category').cat.codes\n",
    "class_names = merged['category'].astype('category').cat.categories\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "561e2d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model trained and saved as 'model2_xgboost.joblib'\n"
     ]
    }
   ],
   "source": [
    "#  Final XGBoost training block (clean, no warnings)\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=len(np.unique(y)),\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    subsample=0.8,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "import joblib\n",
    "joblib.dump(xgb_clf, 'model2_xgboost.joblib')\n",
    "best_model = xgb_clf\n",
    "\n",
    "print(\"âœ… Model trained and saved as 'model2_xgboost.joblib'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc11c26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Holdout file keys: ['X', 'y']\n",
      "ðŸ“„ Predictions saved to 'model2_holdout_predictions.txt'\n"
     ]
    }
   ],
   "source": [
    "# Load holdout dataset\n",
    "holdout_data = np.load('bodmas_holdout.npz')\n",
    "print(\"ðŸ“‚ Holdout file keys:\", holdout_data.files)\n",
    "\n",
    "keys = holdout_data.files\n",
    "if len(keys) < 1:\n",
    "    raise SystemExit(\"âŒ Holdout file is empty.\")\n",
    "elif len(keys) == 1:\n",
    "    X_holdout = holdout_data[keys[0]]\n",
    "    y_holdout = None\n",
    "    print(\"âš ï¸ Only features found. No labels available for evaluation.\")\n",
    "else:\n",
    "    X_holdout = holdout_data[keys[0]]\n",
    "    y_holdout = holdout_data[keys[1]]\n",
    "\n",
    "X_holdout_scaled = scaler.transform(X_holdout)\n",
    "y_pred = best_model.predict(X_holdout_scaled)\n",
    "np.savetxt(\"model2_holdout_predictions.txt\", y_pred, fmt='%d')\n",
    "print(\"ðŸ“„ Predictions saved to 'model2_holdout_predictions.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7a9c5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Evaluation on Holdout Set:\n",
      "\n",
      "Accuracy: 0.0002\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    backdoor       1.00      0.00      0.00     18363\n",
      " cryptominer       0.00      0.00      0.00     16072\n",
      "  downloader       0.00      0.00      0.00         0\n",
      "      trojan       0.00      0.00      0.00         0\n",
      "        worm       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.00     34435\n",
      "   macro avg       0.20      0.00      0.00     34435\n",
      "weighted avg       0.53      0.00      0.00     34435\n",
      "\n",
      "Confusion Matrix:\n",
      " [[    7     0     4 18166   186]\n",
      " [    0     0     0 15820   252]\n",
      " [    0     0     0     0     0]\n",
      " [    0     0     0     0     0]\n",
      " [    0     0     0     0     0]]\n",
      "\n",
      "TPR per class:\n",
      "backdoor: 0.0004\n",
      "cryptominer: 0.0000\n",
      "downloader: 0.0000\n",
      "trojan: 0.0000\n",
      "worm: 0.0000\n",
      "\n",
      "FPR per class:\n",
      "backdoor: 0.0000\n",
      "cryptominer: 0.0000\n",
      "downloader: 0.0001\n",
      "trojan: 0.9870\n",
      "worm: 0.0127\n"
     ]
    }
   ],
   "source": [
    "# Evaluation if labels are available\n",
    "if y_holdout is not None:\n",
    "    print(\"\\nðŸ“Š Evaluation on Holdout Set:\\n\")\n",
    "    acc = accuracy_score(y_holdout, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\\n\")\n",
    "\n",
    "    from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "    labels_in_holdout = unique_labels(y_holdout, y_pred)\n",
    "    class_names_subset = [class_names[i] for i in labels_in_holdout]\n",
    "\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(\n",
    "        y_holdout, y_pred,\n",
    "        labels=labels_in_holdout,\n",
    "        target_names=class_names_subset,\n",
    "        zero_division=0  # âœ… no undefined metric warnings\n",
    "    ))\n",
    "\n",
    "    cm = confusion_matrix(y_holdout, y_pred, labels=labels_in_holdout)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    # âœ… Fix division by zero in TPR\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        TPR = np.nan_to_num(np.diag(cm) / np.sum(cm, axis=1))\n",
    "\n",
    "    FPR = []\n",
    "    for i in range(len(cm)):\n",
    "        FP = np.sum(cm[:, i]) - cm[i, i]\n",
    "        TN = np.sum(cm) - (np.sum(cm[i, :]) + np.sum(cm[:, i]) - cm[i, i])\n",
    "        FPR.append(FP / (FP + TN) if (FP + TN) != 0 else 0.0)\n",
    "\n",
    "    print(\"\\nTPR per class:\")\n",
    "    for i, rate in enumerate(TPR):\n",
    "        print(f\"{class_names_subset[i]}: {rate:.4f}\")\n",
    "\n",
    "    print(\"\\nFPR per class:\")\n",
    "    for i, rate in enumerate(FPR):\n",
    "        print(f\"{class_names_subset[i]}: {rate:.4f}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No labels found in holdout file. Only predictions generated.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3d1516-8ff4-41df-b3e3-1e17a422e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db8fd30-aff7-49ea-a3b3-2e1cda61838a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
