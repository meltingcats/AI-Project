import numpy as np
import pandas as pd

# Load features and labels
data = np.load("bodmas_train_test.npz")
X = data['X']  # feature vectors
y_binary = data['y']  # 0=benign, 1=malware

# Load metadata and category
metadata = pd.read_csv("bodmas_metadata_train_test.csv")  # has 'sha'
categories = pd.read_csv("bodmas_malware_category.csv")   # has 'sha256'

# Merge on correct columns
metadata = metadata.merge(categories, left_on='sha', right_on='sha256', how='left')
metadata['category'] = metadata['category'].fillna('benign')
metadata.drop(columns=['sha256'], inplace=True)

# Combine with features
df = pd.DataFrame(X)
df['category'] = metadata['category']


#Check Shape of Features and Labels

print("Feature matrix shape:", X.shape)
print("Binary label shape:", y_binary.shape)

#Check First Few Rows of Metadata
print(metadata.head())


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Encode category labels to integers
le = LabelEncoder()
y = le.fit_transform(df['category'])
X_features = df.drop(columns=['category'])

# Create train/test sets
X_train, X_test, y_train, y_test = train_test_split(
    X_features, y, test_size=0.2, stratify=y, random_state=42
)


#trying Random Forest Classifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

y_pred = rf.predict(X_test)
print(classification_report(y_test, y_pred, target_names=le.classes_))




from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
import pandas as pd

# --- Train Random Forest Model ---
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# --- Predict ---
y_pred_rf = rf.predict(X_test)

# --- Print Overall Accuracy ---
print("Random Forest - Overall Accuracy:", accuracy_score(y_test, y_pred_rf))

# --- Function to Evaluate Top 10 Classes ---
def limited_accuracy_by_class(y_true, y_pred, class_names, top_n=10):
    counts = pd.Series(y_true).value_counts().nlargest(top_n)
    top_classes = counts.index.tolist()
    cm = confusion_matrix(y_true, y_pred, labels=top_classes)
    output = []

    for i, class_idx in enumerate(top_classes):
        class_name = class_names[class_idx]
        TP = cm[i, i]
        FN = cm[i].sum() - TP
        FP = cm[:, i].sum() - TP
        TN = cm.sum() - (TP + FN + FP)
        acc = (TP + TN) / cm.sum()
        tpr = TP / (TP + FN) if (TP + FN) > 0 else 0
        fpr = FP / (FP + TN) if (FP + TN) > 0 else 0
        output.append([class_name, round(acc, 2), round(tpr, 2), round(fpr, 2)])

    return pd.DataFrame(output, columns=["Class", "Accuracy", "TPR", "FPR"])

# --- Display Evaluation for Top 10 Classes ---
top10_rf_report = limited_accuracy_by_class(y_test, y_pred_rf, le.classes_, top_n=10)
print("\nTop 10 Class Evaluation - Random Forest:")
print(top10_rf_report)
